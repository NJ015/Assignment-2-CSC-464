{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLY8P4_--fVu"
      },
      "source": [
        "## Steps to build the next word recommender system\n",
        "\n",
        "1. Loading and exploring the dataset\n",
        "2. Creating N-grams of the dialogue\n",
        "3. Building the N-gram Language Model\n",
        "4. Predicting the next word using N-gram Language Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TiUr03yo6ce"
      },
      "source": [
        "## 1. Loading and exploring the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "p7C44E64-jZQ"
      },
      "outputs": [],
      "source": [
        "# loading the required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import pickle\n",
        "import random\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'and': 0.5, 'that': 0.5}\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import random\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load Reuters dataset\n",
        "dialogs = pd.read_csv(\"sample_reuters_dataset.csv\")\n",
        "\n",
        "# Clean the dataset\n",
        "def clean_text(text):\n",
        "    text = re.sub(\"[^a-zA-Z' ]\", \"\", text)  # Keep only letters, spaces, and apostrophes\n",
        "    return text.lower()\n",
        "\n",
        "# Clean all sentence_text in the dialogs dataframe\n",
        "dialogs['cleaned_text'] = dialogs['sentence_text'].apply(clean_text)\n",
        "\n",
        "# creating the vocabulary\n",
        "# get list of all the words\n",
        "all_words = \" \".join(dialogs['cleaned_text']).split()\n",
        "words_dict = {}\n",
        "# add word-count pair to the dictionary\n",
        "for word in all_words:\n",
        "    # check if the word is already in dictionary\n",
        "    if word in words_dict:\n",
        "        # increment count of word by 1\n",
        "        words_dict[word] = words_dict[word] + 1\n",
        "    else:\n",
        "        # add the word to dictionary with count 1\n",
        "        words_dict[word] = 1\n",
        "\n",
        "\n",
        "# Create N-grams functions\n",
        "def create_ngram(sentence, n):\n",
        "    tokens = sentence.split()\n",
        "    return [tokens[i:i + n] for i in range(len(tokens) - n + 1)]\n",
        "\n",
        "# Create dataframe with cleaned sentences and N-grams\n",
        "dataset = pd.DataFrame({'Sentences': dialogs['cleaned_text']})\n",
        "dataset['unigram'] = dataset['Sentences'].apply(lambda x: create_ngram(x, 1))\n",
        "dataset['bigram'] = dataset['Sentences'].apply(lambda x: create_ngram(x, 2))\n",
        "dataset['trigram'] = dataset['Sentences'].apply(lambda x: create_ngram(x, 3))\n",
        "\n",
        "# Build N-gram model (trigrams in this case)\n",
        "model = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "for trigrams in dataset['trigram']:\n",
        "    for w1, w2, w3 in trigrams:\n",
        "        model[(w1, w2)][w3] += 1\n",
        "\n",
        "# Convert counts to probabilities\n",
        "for w1_w2 in model:\n",
        "    total_count = float(sum(model[w1_w2].values()))\n",
        "    for w3 in model[w1_w2]:\n",
        "        model[w1_w2][w3] /= total_count\n",
        "\n",
        "# Function to predict the next word based on the trigram model\n",
        "def predict_next_word(w1, w2, model):\n",
        "    if (w1, w2) in model:\n",
        "        return max(model[(w1, w2)], key=model[(w1, w2)].get)\n",
        "    else:\n",
        "        return \"No prediction available\"\n",
        "\n",
        "# Example predictions\n",
        "# print(predict_next_word(\"stock\", \"market\", model))\n",
        "# print(predict_next_word(\"global\", \"economy\", model))\n",
        "\n",
        "print(dict(model[\"am\", \"concerned\"]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create vocabulary\n",
        "vocabulary = set(\" \".join(dialogs['cleaned_text']).split())\n",
        "print(f\"Vocabulary size: {len(vocabulary)}\")\n",
        "print(f\"Vocabulary: {vocabulary}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "wbZM3hu4FMZK",
        "outputId": "f92dc7e0-0841-4cb2-d77c-c20e349cb795"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'european': 1.0}"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# another example\n",
        "dict(model[\"how\", \"are\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "7Wiyawo-FRZo",
        "outputId": "b4ea15bc-69f0-4909-f473-d203ca3a9fe1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'go': 0.3333333333333333,\n",
              " 'have': 0.3333333333333333,\n",
              " 'very': 0.3333333333333333}"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# another example\n",
        "dict(model[\"good\", \"to\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'good': 1.0}"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dict(model[\"to\", \"very\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'nothing': 0.16666666666666666,\n",
              " 'been': 0.3333333333333333,\n",
              " 'mixed': 0.16666666666666666,\n",
              " 'to': 0.16666666666666666,\n",
              " 'talked': 0.16666666666666666}"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dict(model[\"i\", \"have\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved successfully!\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "# Convert defaultdict to normal dict\n",
        "model_dict = {k: dict(v) for k, v in model.items()}\n",
        "\n",
        "# Save model\n",
        "with open(\"trigram_model.pkl\", \"wb\") as f:\n",
        "    pickle.dump(model_dict, f)\n",
        "\n",
        "print(\"Model saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
